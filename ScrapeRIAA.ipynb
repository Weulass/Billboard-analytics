{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the RIAA data is hard to obtain, we have to create a Selenium script and we create the following function to fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "driver = webdriver.Chrome('/Users/iliasmiraoui/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_riaa(artist):\n",
    "    query = artist\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    df = pd.DataFrame(columns=[\"artist\",\"artists\",\"songs\",\"last_certification\",\"label\",\"format\",\"details\"])\n",
    "    url = \"https://www.riaa.com/gold-platinum/?tab_active=default-award&ar=\"+query+\"&lab=&genre=&format=&date_option=release&from=&to=&award=&type=&category=&adv=SEARCH#search_section\"\n",
    "    driver.get(url)\n",
    "    sleep(0.1)\n",
    "    artists = []\n",
    "    songs = []\n",
    "    last_certification = []\n",
    "    label = []\n",
    "    frmat= []\n",
    "    details = []\n",
    "    hascontent =0\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//*[@id='loadmore']\").click()\n",
    "    except:\n",
    "        hascontent =1\n",
    "        sleep(0.3)\n",
    "    to_click = driver.find_elements_by_xpath(\"//*[@class='others_cell format_cell']/div/a\")\n",
    "    for link in to_click:\n",
    "        link.click()\n",
    "        sleep(0.6)\n",
    "    awards = driver.find_elements_by_xpath(\"//*[@class='table_award_row expanded']\")\n",
    "    if hascontent ==1:\n",
    "        awards.extend(driver.find_elements_by_xpath(\"//*[@class='table_award_row expanded hasContent']\"))\n",
    "    nb_songs = len(awards)\n",
    "    for award in awards:\n",
    "        artists.append(award.find_element_by_xpath(\".//*[@class='artists_cell']\").text)\n",
    "        songs.append(award.find_element_by_xpath(\".//*[@class='others_cell']\").text)\n",
    "        last_certification.append(award.find_elements_by_xpath(\".//*[@class='others_cell']\")[1].text)\n",
    "        label.append(award.find_elements_by_xpath(\".//*[@class='others_cell']\")[2].text)\n",
    "        frmat.append(award.find_element_by_xpath(\".//*[@class='others_cell format_cell']\").text)\n",
    "        next_element = award.find_element_by_xpath(\".//following-sibling::tr\")\n",
    "        detail = next_element.find_element_by_xpath(\"//*[@class='table_award_row expanded']\")\n",
    "        details.append([x.text for x in next_element.find_elements_by_xpath(\".//*[@class='content_recent_table']/td\")])\n",
    "    for i in range(nb_songs):\n",
    "        df.loc[i] = [artist,artists[i],songs[i],last_certification[i],label[i],frmat[i],details[i]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import our datasets and start getting the data. (This took ~15hours to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import pickle \n",
    "\n",
    "\n",
    "with open('song_df_100.pkl', 'rb') as f:\n",
    "        song_df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "driver = webdriver.Chrome('/Users/iliasmiraoui/Desktop/chromedriver')\n",
    "pbar = tqdm(song_df[\"artist\"].unique())\n",
    "i = 0\n",
    "for artist in pbar:\n",
    "    if (artist not in artist_df[\"artist\"].unique()) and (artist not in artist_df[0].unique()):\n",
    "        i=i+1\n",
    "        df = get_riaa(artist)\n",
    "        artist_df = artist_df.append(df)\n",
    "        if len(df) == 0:\n",
    "            artist_df = artist_df.append([artist,None,None,None,None,None,None])\n",
    "        print(i)\n",
    "        if i % 5 == 0:\n",
    "            with open('artist_df.pkl', 'wb') as f:\n",
    "                pickle.dump(artist_df, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the Spotify Data, the RIAA search function is very peculiar and will only accept very similar strings. We separate the artists accordingly and we fetch those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keywords = [\"Featuring\",\"Feauring\", \"featuring\", \"&\",\",\",\" X \", \" x \",\"Presents\", \"From\", \"Or\",\"And\",]\n",
    "new_df = artist_df.dropna(subset=[0])\n",
    "temp_list = np.asarray(new_df[0])\n",
    "count=0\n",
    "for keyword in keywords:\n",
    "    artist_list = [i.split(keyword) for i in temp_list]\n",
    "    temp_list = list()\n",
    "    count=count+1\n",
    "    for i in artist_list:\n",
    "            temp_list.extend(i)\n",
    "\n",
    "artist_list = list()\n",
    "for i in temp_list:\n",
    "    i = i.strip()\n",
    "    if len(i)>1:\n",
    "        artist_list.append(i)\n",
    "artist_list = set(artist_list)        \n",
    "artist_list_new = set(artist_list) \n",
    "\n",
    "for i in artist_list:\n",
    "    if len(artist_df[artist_df[0] == i]) >0 and i in artist_list_new:\n",
    "        artist_list_new.remove(i)\n",
    "    elif len(artist_df[artist_df[\"artist\"] == i]) >0 and i in artist_list_new:\n",
    "        artist_list_new.remove(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "driver = webdriver.Chrome('/Users/iliasmiraoui/Desktop/chromedriver')\n",
    "pbar = list(artist_list_new)\n",
    "i = 0\n",
    "for artist in pbar:\n",
    "    if (artist not in artist_df[\"artist\"].unique()) and (artist not in artist_df[0].unique()):\n",
    "        i=i+1\n",
    "        df = get_riaa(artist)\n",
    "        artist_df = artist_df.append(df)\n",
    "        if len(df) == 0:\n",
    "            artist_df = artist_df.append([artist,None,None,None,None,None,None])\n",
    "        print(i)\n",
    "        if i % 5 == 0:\n",
    "            with open('artist_df.pkl', 'wb') as f:\n",
    "                pickle.dump(artist_df, f)\n",
    "with open('artist_df.pkl', 'wb') as f:\n",
    "    pickle.dump(artist_df, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the dataset where the rows are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = artist_df.drop([0],axis=1)  #delete first column, no information\n",
    "artist_df = artist_df.replace(to_replace='None', value=np.nan).dropna() \n",
    "artist_df = artist_df.reset_index()\n",
    "artist_df.pop(\"index\")\n",
    "artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the search function is very peculiar, we check our dataset and clean it accordingly. The data is messy, VERY MESSY. So we look at the messy data points by varying the thresholds below and we manage to clean it by removing the rows as per the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def similar(a, b, threshold=70):\n",
    "    return (fuzz.partial_ratio(a, b) >= threshold)\n",
    "\n",
    "for row in artist_df.index:\n",
    "    if not similar(artist_df.loc[row,\"artist\"].upper(),artist_df.loc[row,\"artists\"]) and (similar(artist_df.loc[row,\"artist\"].upper(),artist_df.loc[row,\"artists\"],95)) and (fuzz.ratio(artist_df.loc[row,\"artist\"].upper(),artist_df.loc[row,\"artists\"]) <=95):\n",
    "        print(fuzz.partial_ratio(artist_df.loc[row,\"artist\"].upper(),artist_df.loc[row,\"artists\"]))\n",
    "        print(row, artist_df.loc[row,\"artist\"],artist_df.loc[row,\"artists\"])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [346,354,360,1831,1832,1833,1835,1842,1844,1846,1849,1850,1851,1855,1856,2441,2443,2447,229,2450,2452,\n",
    "          2849,3278,3282,3286,3296,3297,3298,3299,3300,3301,3302,3523,3590,3604,3765,3769,3809,3810,3811,4057,4079,\n",
    "           4083,4086,4194,4198,4199,4209,4213,4216,4303,4404,4458,4534,5260,5262,5572,5793,5794,5795,5916,5918,5919,\n",
    "           5920,5922,6049,6050,6067,6240,6253,6254,6255,6276,6279,6278,6280,6283,6287,6286,6289,6290,6291,6293,6306,\n",
    "           6815,7053,7056,7271,7272,7273,7274,7597,7598,7599,7600,7791,7793,7794,7795,7798,7799,7800,7804,7805,7812,7818,\n",
    "           8033,8035,8036,8037,8092,8142,8145,8147,8259,8284,8610,8611,8666,8670,8671,8672,8675,8676,8678,8683,8753,8785,8786,8787,\n",
    "           8799,8800,8809,8903,8908,8909,8912,8926,8927,9231,9233,9289,9290,9310,9315,9394,9396,9512,9567,9568,9569,9571,\n",
    "           9602,9627,9628,9771,9796,9799,9800,9846,9848,9851,9891,9892,9893,9894,9957,9959,10043,10044,10169,10170,10204,\n",
    "           10205,10206,10328,10329,10505,10506,10529,10567,10573,10624,10695,10745,10746,10915,10989,10995,11100,11133,\n",
    "           11141,11144,11234,11297,11298,11341,11348,11520,11521,11522,11624,11625,11626,11807,11808,11809,11814,11817,\n",
    "           12298,12495,12501,12502,12503,12931,12936,12937,\n",
    "          ]\n",
    "\n",
    "to_drop.extend([i for i in range(13342,13372)])\n",
    "to_drop.extend([i for i in range(13268,13309)])\n",
    "to_drop.extend([i for i in range(13233,13259)])\n",
    "to_drop.extend([i for i in range(13191,13232)])\n",
    "to_drop.extend([i for i in range(13159,13187)])\n",
    "to_drop.extend([i for i in range(13147,13158)])\n",
    "to_drop.extend([i for i in range(13105,13135)])\n",
    "to_drop.extend([i for i in range(13061,13086)])\n",
    "to_drop.extend([i for i in range(13013,13043)])\n",
    "to_drop.extend([i for i in range(12951,12999)])\n",
    "to_drop.extend([i for i in range(12907,12930)])\n",
    "to_drop.extend([i for i in range(12895,12903)])\n",
    "to_drop.extend([i for i in range(12881,12894)])\n",
    "to_drop.extend([i for i in range(12844,12855)])\n",
    "to_drop.extend([i for i in range(12813,12843)])\n",
    "to_drop.extend([i for i in range(12758,12794)])\n",
    "to_drop.extend([i for i in range(12743,12756)])\n",
    "to_drop.extend([i for i in range(12694,12740)])\n",
    "to_drop.extend([i for i in range(12643,12672)])\n",
    "to_drop.extend([i for i in range(12592,12626)])\n",
    "to_drop.extend([i for i in range(12547,12577)])\n",
    "to_drop.extend([i for i in range(12458,12486)])\n",
    "to_drop.extend([i for i in range(12391,12420)])\n",
    "to_drop.extend([i for i in range(12374,12377)])\n",
    "to_drop.extend([i for i in range(12303,12364)])\n",
    "to_drop.extend([i for i in range(12239,12269)])\n",
    "to_drop.extend([i for i in range(12196,12226)])\n",
    "to_drop.extend([i for i in range(12146,12176)])\n",
    "to_drop.extend([i for i in range(12081,12111)])\n",
    "to_drop.extend([i for i in range(12027,12079)])\n",
    "to_drop.extend([i for i in range(12017,12025)])\n",
    "to_drop.extend([i for i in range(11986,11997)])\n",
    "to_drop.extend([i for i in range(11945,11980)])\n",
    "to_drop.extend([i for i in range(11904,11935)])\n",
    "to_drop.extend([i for i in range(11868,11887)])\n",
    "to_drop.extend([i for i in range(11831,11860)])\n",
    "to_drop.extend([i for i in range(11818,11827)])\n",
    "to_drop.extend([i for i in range(11810,11813)])\n",
    "to_drop.extend([i for i in range(11776,11798)])\n",
    "to_drop.extend([i for i in range(11773,11775)])\n",
    "to_drop.extend([i for i in range(11593,11623)])\n",
    "to_drop.extend([i for i in range(11547,11549)])\n",
    "to_drop.extend([i for i in range(11537,11545)])\n",
    "to_drop.extend([i for i in range(11527,11534)])\n",
    "to_drop.extend([i for i in range(11484,11503)])\n",
    "to_drop.extend([i for i in range(11407,11467)])\n",
    "to_drop.extend([i for i in range(11357,11394)])\n",
    "to_drop.extend([i for i in range(11235,11251)])\n",
    "to_drop.extend([i for i in range(11147,11184)])\n",
    "to_drop.extend([i for i in range(11137,11140)])\n",
    "to_drop.extend([i for i in range(11102,11129)])\n",
    "to_drop.extend([i for i in range(11086,11098)])\n",
    "to_drop.extend([i for i in range(11065,11083)])\n",
    "to_drop.extend([i for i in range(11000,11011)])\n",
    "to_drop.extend([i for i in range(10997,10999)])\n",
    "to_drop.extend([i for i in range(10917,10931)])\n",
    "to_drop.extend([i for i in range(10877,10882)])\n",
    "to_drop.extend([i for i in range(10822,10829)])\n",
    "to_drop.extend([i for i in range(10809,10815)])\n",
    "to_drop.extend([i for i in range(10767,10796)])\n",
    "to_drop.extend([i for i in range(10749,10758)])\n",
    "to_drop.extend([i for i in range(10709,10743)])\n",
    "to_drop.extend([i for i in range(10699,10707)])\n",
    "to_drop.extend([i for i in range(10658,10686)])\n",
    "to_drop.extend([i for i in range(10625,10639)])\n",
    "to_drop.extend([i for i in range(10593,10622)])\n",
    "to_drop.extend([i for i in range(10475,10496)])\n",
    "to_drop.extend([i for i in range(10445,10451)])\n",
    "to_drop.extend([i for i in range(10331,10340)])\n",
    "to_drop.extend([i for i in range(10296,10324)])\n",
    "to_drop.extend([i for i in range(10269,10277)])\n",
    "to_drop.extend([i for i in range(10237,10267)])\n",
    "to_drop.extend([i for i in range(10109,10139)])\n",
    "to_drop.extend([i for i in range(10079,10108)])\n",
    "to_drop.extend([i for i in range(10045,10072)])\n",
    "to_drop.extend([i for i in range(10010,10040)])\n",
    "to_drop.extend([i for i in range(9984,9995)])\n",
    "to_drop.extend([i for i in range(9940,9944)])\n",
    "to_drop.extend([i for i in range(9913,9935)])\n",
    "to_drop.extend([i for i in range(9852,9882)])\n",
    "to_drop.extend([i for i in range(9712,9740)])\n",
    "to_drop.extend([i for i in range(9539,9562)])\n",
    "to_drop.extend([i for i in range(9438,9468)])\n",
    "to_drop.extend([i for i in range(9316,9346)])\n",
    "to_drop.extend([i for i in range(9291,9300)])\n",
    "to_drop.extend([i for i in range(9250,9280)])\n",
    "to_drop.extend([i for i in range(9197,9201)])\n",
    "to_drop.extend([i for i in range(9076,9080)])\n",
    "to_drop.extend([i for i in range(9006,9011)])\n",
    "to_drop.extend([i for i in range(8877,8892)])\n",
    "to_drop.extend([i for i in range(362,376)])\n",
    "to_drop.extend([i for i in range(1836,1830)])\n",
    "to_drop.extend([i for i in range(1857,1861)])\n",
    "to_drop.extend([i for i in range(2427,2430)])\n",
    "to_drop.extend([i for i in range(2427,2430)])\n",
    "to_drop.extend([i for i in range(2803,2808)])\n",
    "to_drop.extend([i for i in range(2427,2430)])\n",
    "to_drop.extend([i for i in range(2962,2967)])\n",
    "to_drop.extend([i for i in range(3481,3493)])\n",
    "to_drop.extend([i for i in range(3591,3602)])\n",
    "to_drop.extend([i for i in range(3607,3620)])\n",
    "to_drop.extend([i for i in range(3812,3838)])\n",
    "to_drop.extend([i for i in range(4058,4073)])\n",
    "to_drop.extend([i for i in range(4268,4276)])\n",
    "to_drop.extend([i for i in range(4277,4297)])\n",
    "to_drop.extend([i for i in range(4303,4332)])\n",
    "to_drop.extend([i for i in range(4410,4425)])\n",
    "to_drop.extend([i for i in range(5064,5069)])\n",
    "to_drop.extend([i for i in range(5574,5589)])\n",
    "to_drop.extend([i for i in range(5873,5903)])\n",
    "to_drop.extend([i for i in range(5923,5931)])\n",
    "to_drop.extend([i for i in range(6296,6305)])\n",
    "to_drop.extend([i for i in range(6310,6322)])\n",
    "to_drop.extend([i for i in range(6787,6791)])\n",
    "to_drop.extend([i for i in range(6822,6827)])\n",
    "to_drop.extend([i for i in range(6832,6862)])\n",
    "to_drop.extend([i for i in range(7009,7039)])\n",
    "to_drop.extend([i for i in range(7057,7065)])\n",
    "to_drop.extend([i for i in range(7066,7096)])\n",
    "to_drop.extend([i for i in range(7136,7165)])\n",
    "to_drop.extend([i for i in range(7257,7270)])\n",
    "to_drop.extend([i for i in range(7779,7790)])\n",
    "to_drop.extend([i for i in range(7808,7812)])\n",
    "to_drop.extend([i for i in range(7822,7831)])\n",
    "to_drop.extend([i for i in range(7840,7843)])\n",
    "to_drop.extend([i for i in range(7846,7863)])\n",
    "to_drop.extend([i for i in range(7871,7873)])\n",
    "to_drop.extend([i for i in range(7876,7899)])\n",
    "to_drop.extend([i for i in range(7257,7270)])\n",
    "to_drop.extend([i for i in range(8148,8153)])\n",
    "to_drop.extend([i for i in range(8264,8274)])\n",
    "to_drop.extend([i for i in range(8396,8411)])\n",
    "to_drop.extend([i for i in range(8418,8437)])\n",
    "to_drop.extend([i for i in range(8438,8441)])\n",
    "to_drop.extend([i for i in range(8442,8447)])\n",
    "to_drop.extend([i for i in range(8495,8503)])\n",
    "to_drop.extend([i for i in range(8506,8523)])\n",
    "to_drop.extend([i for i in range(8653,8665)])\n",
    "to_drop.extend([i for i in range(8792,8797)])\n",
    "to_drop.extend([i for i in range(8815,8840)])\n",
    "\n",
    "for i in to_drop:\n",
    "    if i in artist_df.index:\n",
    "        artist_df =artist_df.drop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [244,3772,4554,4726,6124,6126,6127,7391,7591,8000,8001,8002,8649,8910,8911,8928,10876,11101,11349,11350,11353,\n",
    "          11507,11508,11509,11656,12283,12425]\n",
    "\n",
    "to_drop.extend([i for i in range(4649,4653)])\n",
    "to_drop.extend([i for i in range(4730,4736)])\n",
    "to_drop.extend([i for i in range(5843,5873)])\n",
    "to_drop.extend([i for i in range(7990,7999)])\n",
    "to_drop.extend([i for i in range(8904,8908)])\n",
    "to_drop.extend([i for i in range(8913,8917)])\n",
    "to_drop.extend([i for i in range(9067,9069)])\n",
    "to_drop.extend([i for i in range(10370,10386)])\n",
    "to_drop.extend([i for i in range(11026,11056)])\n",
    "to_drop.extend([i for i in range(11658,11686)])\n",
    "to_drop.extend([i for i in range(11827,11830)])\n",
    "to_drop.extend([i for i in range(11892,11901)])\n",
    "\n",
    "for i in to_drop:\n",
    "    if i in artist_df.index:\n",
    "        artist_df =artist_df.drop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [3931,303,4425,4426,5532,4433,4434,7588,7761,8900,8901,8902,8949,9061,9346,9347,9348,9350,9351,9356,9357,9958,\n",
    "          9960,9961,10882,10883,10994,10996,10999,11011,11352,11354,11714,11716,11721,13066,13067]\n",
    "\n",
    "to_drop.extend([i for i in range(3908,3917)])\n",
    "to_drop.extend([i for i in range(3923,3930)])\n",
    "to_drop.extend([i for i in range(3933,3937)])\n",
    "to_drop.extend([i for i in range(7593,7597)])\n",
    "to_drop.extend([i for i in range(8644,8653)])\n",
    "to_drop.extend([i for i in range(8917,8922)])\n",
    "to_drop.extend([i for i in range(9362,9376)])\n",
    "to_drop.extend([i for i in range(10229,10235)])\n",
    "to_drop.extend([i for i in range(11012,11019)])\n",
    "to_drop.extend([i for i in range(11342,11348)])\n",
    "to_drop.extend([i for i in range(11693,11697)])\n",
    "to_drop.extend([i for i in range(11269,11297)])\n",
    "\n",
    "for i in to_drop:\n",
    "    if i in artist_df.index:\n",
    "        artist_df =artist_df.drop(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now clean the RIAA output into clear \"Platinum\" \"Gold\" and number of award for each date an award is given for a song and we save the dataframe for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.DataFrame(columns=[\"artist\",\"artists\",\"award\",\"award_date\",\"format\",\"label\",\"last_certification\",\"songs\"])\n",
    "df2 = artist_df\n",
    "l = df2['details'].tolist()\n",
    "for i in range(len(df2)):\n",
    "    certif = ['Platinum', 'Gold']\n",
    "    new_l = []\n",
    "    for j in range(len(l[i])):\n",
    "        for word in certif:\n",
    "            if word in l[i][j]:\n",
    "                new_l.append(l[i][j])\n",
    "                artist = df2.iloc[i][0]\n",
    "                artists = df2.iloc[i][1]\n",
    "                award = l[i][j].split(\"|\")[0]\n",
    "                award_date = l[i][j].split(\"|\")[1]\n",
    "                label = df2.iloc[i][4]\n",
    "                formats = df2.iloc[i][3]\n",
    "                last_certif = df2.iloc[i][5]\n",
    "                songs = df2.iloc[i][6]\n",
    "                n_df.loc[len(n_df)] = [artist,artists,award,award_date,formats,label,last_certif,songs]\n",
    "for row in n_df.index:\n",
    "    award = n_df.loc[row,\"award\"].split(\"x \")\n",
    "    if len(award)>1:\n",
    "        n_df.loc[row,\"award\"] = \"Platinum\"\n",
    "        n_df.loc[row,\"award_num\"] = int(award[0])\n",
    "    else:\n",
    "        n_df.loc[row,\"award_num\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('riaa_df.pkl', 'wb') as f:\n",
    "    pickle.dump(n_df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
